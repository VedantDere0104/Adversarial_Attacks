{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Targeted_FGSM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPvwtcWayUox"
      },
      "source": [
        "####"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsRce4w_yYGU"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader , Dataset\n",
        "from torchvision import datasets , transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFlUexPHzA_0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn8HbpCE-UVJ"
      },
      "source": [
        "alpha = 1\n",
        "eps = 60\n",
        "scale = 1\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXy9pqRnz0CA"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=2, size=(1 , 28 , 28)):\n",
        "  image_shifted = image_tensor\n",
        "  image_unflat = image_shifted.detach().cpu().view(-1, *size)\n",
        "  image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "  plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMyLpOEE6SAj"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model , self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1 , 10 , kernel_size = 5)\n",
        "        self.conv2 = nn.Conv2d(10 , 20 , kernel_size=5)\n",
        "        self.dropout2d = nn.Dropout2d()\n",
        "\n",
        "        self.fc1 = nn.Linear(320 , 50)\n",
        "        self.fc2 = nn.Linear(50 , 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1d = nn.Dropout()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2 , stride=2)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.relu(self.maxpool(self.conv1(x)))\n",
        "        x = self.relu(self.dropout2d(self.maxpool(self.conv2(x))))\n",
        "        x = x.view(-1 , 320)\n",
        "        x = self.fc1(x)\n",
        "        x = self.softmax(self.fc2(x))\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5uN_OF6eGm"
      },
      "source": [
        "model = Model().to(device)\n",
        "x = torch.randn(2 , 1 , 28 , 28).to(device)\n",
        "z = model(x)\n",
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtPDP-Fm6gGx"
      },
      "source": [
        "\n",
        "test_dataloader = DataLoader(\n",
        "    datasets.MNIST(\n",
        "        '../data' , \n",
        "        train = False , \n",
        "        transform = transforms.Compose([transforms.ToTensor()]) , \n",
        "        download = True\n",
        "    ) , \n",
        "    batch_size = 1 , \n",
        "    shuffle = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2IflDE96iM5"
      },
      "source": [
        "for x , y in test_dataloader:\n",
        "    show_tensor_images(x)\n",
        "    print(y)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFSdJi9F6kB5"
      },
      "source": [
        "pretrained_model = '/content/drive/MyDrive/lenet_mnist_model.pth'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ACyexA_6t_R"
      },
      "source": [
        "model = Model().to(device)\n",
        "model.load_state_dict(torch.load(pretrained_model, map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlWCBQ_x62pp"
      },
      "source": [
        "def target_fgsm(model , loss , image , target_label , scale , eps , alpha , iters = 0):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = target_label.to(device)\n",
        "    clamp_max = 255\n",
        "\n",
        "    if iters == 0:\n",
        "        iters = int(min(eps + 4, 1.25*eps))\n",
        "    if scale :\n",
        "        eps = eps / 255\n",
        "        clamp_max = clamp_max / 255\n",
        "    \n",
        "    for i in range(iters):\n",
        "        image.requires_grad = True\n",
        "        output = model(image)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        model_loss = loss(output , label)\n",
        "        model_loss.backward()\n",
        "\n",
        "        adversarial_image = image - alpha * image.grad.sign()\n",
        "        # a = max{0, X-eps}\n",
        "        a = torch.clamp(image - eps, min=0)\n",
        "        # b = max{a, X'}\n",
        "        b = (adversarial_image>=a).float()*adversarial_image + (a>adversarial_image).float()*a\n",
        "        # c = min{X+eps, b}\n",
        "        c = (b > image+eps).float()*(image+eps) + (image+eps >= b).float()*b\n",
        "        # d = min{255, c}\n",
        "        image = torch.clamp(c, max=clamp_max).detach_()\n",
        "    return image"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ3Un7Ey8lQs"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0_RjXMa8pSJ"
      },
      "source": [
        "def attack(model , dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for image , label in dataloader:\n",
        "        label = label.to(device)\n",
        "        image = image.to(device)\n",
        "        adversarial_image = target_fgsm(model , loss , image , torch.tensor([2]) , scale , eps , alpha)\n",
        "        output = model(adversarial_image)\n",
        "        _ , output = torch.max(output.data , 1)\n",
        "        total += 1\n",
        "        correct +=  (output == label).sum()\n",
        "        #show_tensor_images(adversarial_image)\n",
        "    print(total , correct , total-correct)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cVMFe1s-GFc"
      },
      "source": [
        "attack(model , test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8inkC4OJ-KBR"
      },
      "source": [
        "def test(model , dataloader , epsilon , device):\n",
        "    adv_examples = []\n",
        "    correct = 0\n",
        "\n",
        "    for data , target in dataloader:\n",
        "        data , target = data.to(device) , target.to(device)\n",
        "\n",
        "        data.requires_grad = True\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1 , keepdim = True)[1]\n",
        "\n",
        "        #if init_pred != target:\n",
        "        #    continue\n",
        "        \n",
        "\n",
        "       \n",
        "        adversarial_image = target_fgsm(model , loss , data , target , scale , eps , alpha )\n",
        "\n",
        "        output = model(adversarial_image)\n",
        "        final_output = output.max(1 , keepdim = True)[1]\n",
        "\n",
        "        if final_output.item() == target.item():\n",
        "            correct += 1\n",
        "            if (len(adv_examples) < 5):\n",
        "                adv_ex = adversarial_image.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_output.item(), adv_ex) )\n",
        "                print('Appended')\n",
        "\n",
        "            if ((len(adv_examples) == 5)):\n",
        "                break\n",
        "\n",
        "    final_accuracy = correct/float(len(dataloader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(dataloader), final_accuracy))\n",
        "    return final_accuracy , adv_examples"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8HbeVB9Cobd"
      },
      "source": [
        "epsilon = [70]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlEgYmh1CYe8"
      },
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "for eps in epsilon:\n",
        "    acc, ex = test(model, test_dataloader, eps , device)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxmStAHSCsYZ"
      },
      "source": [
        "\n",
        "cnt = 0\n",
        "plt.figure(figsize=(8,10))\n",
        "for i in range(len(epsilon)):\n",
        "    for j in range(len(examples[i])):\n",
        "        cnt += 1\n",
        "        plt.subplot(len(epsilon),len(examples[0]),cnt)\n",
        "        plt.xticks([], [])\n",
        "        plt.yticks([], [])\n",
        "        if j == 0:\n",
        "            plt.ylabel(\"Eps: {}\".format(epsilon[i]), fontsize=14)\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        plt.title(\"{} -> {}\".format(orig, adv))\n",
        "        plt.imshow(ex, cmap=\"gray\")\n",
        " \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h72GV-iKjbBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}